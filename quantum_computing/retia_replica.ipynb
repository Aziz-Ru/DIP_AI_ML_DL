{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a72746ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 20:30:00.469096: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-24 20:30:00.478424: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-24 20:30:00.563673: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-24 20:30:00.630986: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758724200.694951   16781 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758724200.707990   16781 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1758724200.861772   16781 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758724200.861789   16781 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758724200.861791   16781 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758724200.861792   16781 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-24 20:30:00.879846: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BaseEstimator' from 'qiskit.primitives' (/home/silicon/opencv_learn/.venv/lib/python3.12/site-packages/qiskit/primitives/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcircuit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlibrary\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RealAmplitudes, ZZFeatureMap\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantum_info\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparsePauliOp\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit_machine_learning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mneural_networks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EstimatorQNN\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit_machine_learning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnectors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TorchConnector\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit_algorithms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m algorithm_globals\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opencv_learn/.venv/lib/python3.12/site-packages/qiskit_machine_learning/neural_networks/__init__.py:60\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# This code is part of a Qiskit project.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# (C) Copyright IBM 2019, 2024.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# copyright notice, and modified files need to carry a notice indicating\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# that they have been altered from the originals.\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03mQuantum neural networks (:mod:`qiskit_machine_learning.neural_networks`)\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m========================================================================\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m \u001b[33;03m   LocalEffectiveDimension\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01meffective_dimension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EffectiveDimension, LocalEffectiveDimension\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mestimator_qnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EstimatorQNN\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mneural_network\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NeuralNetwork\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opencv_learn/.venv/lib/python3.12/site-packages/qiskit_machine_learning/neural_networks/effective_dimension.py:23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m algorithm_globals\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QiskitMachineLearningError\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mestimator_qnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EstimatorQNN\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mneural_network\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NeuralNetwork\n\u001b[32m     26\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opencv_learn/.venv/lib/python3.12/site-packages/qiskit_machine_learning/neural_networks/estimator_qnn.py:24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcircuit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Parameter, QuantumCircuit\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprimitives\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseEstimatorV2\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprimitives\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, BaseEstimatorV1, Estimator, EstimatorResult\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantum_info\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparsePauliOp\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantum_info\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moperators\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase_operator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseOperator\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'BaseEstimator' from 'qiskit.primitives' (/home/silicon/opencv_learn/.venv/lib/python3.12/site-packages/qiskit/primitives/__init__.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    " \n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "import os \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fc5641",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_globals.random_seed = 42\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    \"\"\"Modified ResNet-inspired feature extractor for MNIST\"\"\"\n",
    "    def __init__(self, input_channels=1, output_dim=8):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Batch normalization\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Dimension reduction layers (key improvement from the paper)\n",
    "        self.conv_reduce = nn.Conv2d(128, 16, kernel_size=1)  # 1x1 conv for dimension reduction\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # Final dimension reduction to match quantum circuit qubits\n",
    "        self.fc_reduce = nn.Linear(16, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feature extraction\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))\n",
    "\n",
    "        # Dimension reduction (paper's key contribution)\n",
    "        x = torch.relu(self.conv_reduce(x))\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Final reduction to quantum circuit input size\n",
    "        x = torch.tanh(self.fc_reduce(x))  # Tanh to keep values in [-1, 1] for angle embedding\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "class QuantumConvolutionalLayer:\n",
    "    \"\"\"Quantum Convolutional Layer as described in the paper\"\"\"\n",
    "    def __init__(self, num_qubits):\n",
    "        self.num_qubits = num_qubits\n",
    "\n",
    "    def create_circuit(self):\n",
    "        qc = QuantumCircuit(self.num_qubits)\n",
    "\n",
    "        # Parameterized gates for quantum convolution\n",
    "        params = []\n",
    "        for i in range(self.num_qubits - 1):\n",
    "            # RY and RZ gates as shown in Figure 3 of the paper\n",
    "            theta_y = Parameter(f'theta_y_{i}')\n",
    "            theta_z = Parameter(f'theta_z_{i}')\n",
    "            params.extend([theta_y, theta_z])\n",
    "\n",
    "            qc.ry(theta_y, i)\n",
    "            qc.rz(theta_z, i)\n",
    "            qc.cx(i, i+1)\n",
    "\n",
    "        return qc, params\n",
    "#\n",
    "class QuantumPoolingLayer:\n",
    "    \"\"\"Quantum Pooling Layer as described in the paper\"\"\"\n",
    "    def __init__(self, num_qubits):\n",
    "        self.num_qubits = num_qubits\n",
    "\n",
    "    def create_circuit(self):\n",
    "        qc = QuantumCircuit(self.num_qubits)\n",
    "\n",
    "        # Pooling operation - reduces qubits by half\n",
    "        params = []\n",
    "        for i in range(0, self.num_qubits-1, 2):\n",
    "            theta_y = Parameter(f'pool_y_{i}')\n",
    "            theta_z = Parameter(f'pool_z_{i}')\n",
    "            params.extend([theta_y, theta_z])\n",
    "\n",
    "            qc.ry(theta_y, i)\n",
    "            qc.rz(theta_z, i)\n",
    "            qc.cx(i, i+1)\n",
    "\n",
    "        return qc, params\n",
    "\n",
    "#\n",
    "def create_quantum_neural_network(num_qubits=8):\n",
    "    \"\"\"Create the Quantum Neural Network (VQC) as used in the paper\"\"\"\n",
    "\n",
    "    # Feature map for angle embedding\n",
    "    feature_map = ZZFeatureMap(feature_dimension=num_qubits, reps=1)\n",
    "\n",
    "    # Variational ansatz\n",
    "    ansatz = RealAmplitudes(num_qubits, reps=3)\n",
    "\n",
    "    # Create the complete quantum circuit\n",
    "    qc = QuantumCircuit(num_qubits)\n",
    "    qc.compose(feature_map, inplace=True)\n",
    "    qc.compose(ansatz, inplace=True)\n",
    "\n",
    "    # Observable for measurement\n",
    "    observable = SparsePauliOp.from_list([(\"Z\" + \"I\" * (num_qubits-1), 1.0)])\n",
    "\n",
    "    # Create QNN\n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=qc,\n",
    "        observables=observable,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters,\n",
    "    )\n",
    "\n",
    "    return qnn\n",
    "\n",
    "\n",
    "class HybridQuantumNeuralNetwork(nn.Module):\n",
    "    \"\"\"Complete Hybrid Classical-Quantum Neural Network\"\"\"\n",
    "    def __init__(self, num_qubits=8, num_classes=10):\n",
    "        super(HybridQuantumNeuralNetwork, self).__init__()\n",
    "\n",
    "        # Classical feature extractor\n",
    "        self.feature_extractor = FeatureExtractor(output_dim=num_qubits)\n",
    "\n",
    "        # Quantum neural network\n",
    "        self.qnn = create_quantum_neural_network(num_qubits)\n",
    "        self.quantum_layer = TorchConnector(self.qnn)\n",
    "\n",
    "        # Classical output layer\n",
    "        self.classifier = nn.Linear(1, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features using classical network\n",
    "        features = self.feature_extractor(x)\n",
    "\n",
    "        # Process through quantum network\n",
    "        quantum_output = self.quantum_layer(features)\n",
    "\n",
    "        # Final classification\n",
    "        output = self.classifier(quantum_output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "def load_and_preprocess_mnist():\n",
    "    \"\"\"Load and preprocess MNIST dataset\"\"\"\n",
    "    # Load MNIST dataset\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "    # Normalize pixel values\n",
    "    x_train = x_train.astype('float32') / 255.0\n",
    "    x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "    # Add channel dimension\n",
    "    x_train = x_train.reshape(-1, 1, 28, 28)\n",
    "    x_test = x_test.reshape(-1, 1, 28, 28)\n",
    "\n",
    "    # Use a subset for faster training (as in the paper with 780 samples)\n",
    "    # Sample 1000 training samples and 200 test samples\n",
    "    indices = np.random.choice(len(x_train), len(x_train), replace=False)\n",
    "    x_train_subset = x_train[indices]\n",
    "    y_train_subset = y_train[indices]\n",
    "\n",
    "    indices_test = np.random.choice(len(x_test), len(x_test), replace=False)\n",
    "    x_test_subset = x_test[indices_test]\n",
    "    y_test_subset = y_test[indices_test]\n",
    "\n",
    "    return x_train_subset, y_train_subset, x_test_subset, y_test_subset\n",
    "\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate performance metrics as in the paper\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def train_hybrid_model(no_of_epochs=5,learning_rate=0.001,graph_filename='ok.png',experiment_no=0):\n",
    "    \"\"\"Train the hybrid quantum neural network\"\"\"\n",
    "    print(\"Loading and preprocessing MNIST dataset...\")\n",
    "    x_train, y_train, x_test, y_test = load_and_preprocess_mnist()\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    x_train_tensor = torch.FloatTensor(x_train)\n",
    "    y_train_tensor = torch.LongTensor(y_train)\n",
    "    x_test_tensor = torch.FloatTensor(x_test)\n",
    "    y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    print(\"Creating hybrid quantum neural network...\")\n",
    "    model = HybridQuantumNeuralNetwork(num_qubits=8, num_classes=10)\n",
    "\n",
    "    # Loss function and optimizer (using COBYLA equivalent - Adam for neural parts)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(\"Training the model...\")\n",
    "    train_losses = []\n",
    "    history = {\n",
    "        \"experiment_no\":[],\n",
    "        \"epochs\":[],\n",
    "        # \"batch\":[],\n",
    "        \"train_loss\": [],\n",
    "        \"train_accuracy\": []\n",
    "        }\n",
    "    metric_history={\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1_score': []\n",
    "    }\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(no_of_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            try:\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                num_batches += 1\n",
    "                predictions = torch.argmax(output, dim=1)\n",
    "                correct += (predictions == target).sum().item()\n",
    "                total += target.size(0)\n",
    "                acc=(predictions == target).sum().item()/target.size(0)\n",
    "\n",
    "                if batch_idx % 5 == 0:\n",
    "                    print(f'Epoch {epoch+1}/{no_of_epochs}, Batch {batch_idx}, Loss: {loss.item():.4f}, Accuracy:{acc:.4f}')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in batch {batch_idx}: {e}\")\n",
    "                continue\n",
    "\n",
    "        avg_loss = epoch_loss / num_batches if num_batches > 0 else 0\n",
    "        accuracy = correct / total if total > 0 else 0\n",
    "        history[\"train_loss\"].append(avg_loss)\n",
    "        history[\"train_accuracy\"].append(accuracy)\n",
    "        history[\"experiment_no\"].append(experiment_no)\n",
    "        history['epochs'].append(epoch)\n",
    "        # history['batch'].append('Epoch Level')\n",
    "\n",
    "        train_losses.append(avg_loss)\n",
    "        print(f'Epoch {epoch+1}/{no_of_epochs} completed. Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "    print(\"Evaluating the model...\")\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    # Accuracy, precision, recall, F1-score are computed once after training is done.\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            try:\n",
    "                output = model(data)\n",
    "                predictions = torch.argmax(output, dim=1)\n",
    "                all_predictions.extend(predictions.cpu().numpy())\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "            except Exception as e:\n",
    "                print(f\"Error in evaluation: {e}\")\n",
    "                continue\n",
    "\n",
    "    # Calculate metrics\n",
    "    if all_predictions and all_targets:\n",
    "        metrics = calculate_metrics(all_targets, all_predictions)\n",
    "        metric_history['accuracy'].append(metrics['accuracy'])\n",
    "        metric_history['precision'].append(metrics['precision'])\n",
    "        metric_history['recall'].append(metrics['recall'])\n",
    "        metric_history['f1_score'].append(metrics['f1_score'])\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"HYBRID QUANTUM NEURAL NETWORK RESULTS\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Accuracy: {metrics['accuracy']:.3f}\")\n",
    "        print(f\"Precision: {metrics['precision']:.3f}\")\n",
    "        print(f\"Recall: {metrics['recall']:.3f}\")\n",
    "        print(f\"F1-Score: {metrics['f1_score']:.3f}\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        # Plot training loss\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(train_losses, 'b-', label='Training Loss')\n",
    "        plt.title('Hybrid Quantum Neural Network - Training Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(graph_filename)\n",
    "        plt.show()\n",
    "\n",
    "        return model,metric_history, history\n",
    "    else:\n",
    "        print(\"No predictions were generated successfully.\")\n",
    "        return None, None,None\n",
    "\n",
    "\n",
    "\n",
    "def demonstrate_quantum_circuits():\n",
    "    \"\"\"Demonstrate the quantum circuits used in the paper\"\"\"\n",
    "    print(\"\\nDemonstrating Quantum Circuit Components:\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Quantum Convolutional Layer\n",
    "    print(\"1. Quantum Convolutional Layer (2-qubit example):\")\n",
    "    qconv = QuantumConvolutionalLayer(2)\n",
    "    qc_conv, params_conv = qconv.create_circuit()\n",
    "    print(qc_conv.draw())\n",
    "    print(f\"Parameters: {[p.name for p in params_conv]}\")\n",
    "\n",
    "    # Quantum Pooling Layer\n",
    "    print(\"\\n2. Quantum Pooling Layer (2-qubit example):\")\n",
    "    qpool = QuantumPoolingLayer(2)\n",
    "    qc_pool, params_pool = qpool.create_circuit()\n",
    "    print(qc_pool.draw())\n",
    "    print(f\"Parameters: {[p.name for p in params_pool]}\")\n",
    "\n",
    "    # Feature Map (Angle Embedding)\n",
    "    print(\"\\n3. Feature Map for Angle Embedding (4-qubit example):\")\n",
    "    feature_map = ZZFeatureMap(4, reps=1)\n",
    "    print(feature_map.draw())\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the complete implementation\"\"\"\n",
    "    print(\"Enhanced Hybrid Quantum Neural Network for Image Classification\")\n",
    "    print(\"Based on: 'Enhanced Hybrid Quantum Neural Network for Breast Cancer Detection'\")\n",
    "    print(\"Adapted for MNIST digit classification\")\n",
    "    print(\"\\n\")\n",
    "    execution_count = get_ipython().execution_count\n",
    "    cwd = os.getcwd()\n",
    "    new_dir = os.path.join(cwd,f'experiment_{execution_count}')\n",
    "    os.makedirs(new_dir,exist_ok=True)\n",
    "    train_metrics_path = os.path.join(new_dir,'train_metrics.csv')\n",
    "    test_metrics_path = os.path.join(new_dir,'test_metrics.csv')\n",
    "    graph_filename = os.path.join(new_dir,'graph.png')\n",
    "    # Demonstrate quantum circuits\n",
    "    # demonstrate_quantum_circuits()val_accuracy\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    print(\"\\nStarting training process...\")\n",
    "\n",
    "    model, metrics,history = train_hybrid_model(no_of_epochs=10,graph_filename=graph_filename,experiment_no=execution_count)\n",
    "\n",
    "    if model is not None:\n",
    "        train=pd.DataFrame(history)\n",
    "        train.to_csv(train_metrics_path)\n",
    "        test=pd.DataFrame(metrics)\n",
    "        test.to_csv(test_metrics_path)\n",
    "\n",
    "        print(\"\\nTraining completed successfully!\")\n",
    "        print(\"The model combines classical feature extraction with quantum neural networks\")\n",
    "        print(\"Key innovations from the paper:\")\n",
    "        print(\"- Convolutional layer for dimension reduction (instead of fully connected)\")\n",
    "        print(\"- Hybrid classical-quantum architecture\")\n",
    "        print(\"- Angle embedding for quantum feature encoding\")\n",
    "        print(\"- Variational Quantum Classifier (VQC)\")\n",
    "    else:\n",
    "        print(\"Training failed. Please check the setup and try again.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if required libraries are available\n",
    "    try:\n",
    "        main()\n",
    "    except ImportError as e:\n",
    "        print(f\"Missing required library: {e}\")\n",
    "        print(\"Please install required packages:\")\n",
    "        print(\"pip install qiskit==2.2.0 qiskit-aer qiskit-machine-learning qiskit-algorithms\")\n",
    "        print(\"pip install torch torchvision tensorflow matplotlib scikit-learn\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"Please check your environment setup.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv_learn (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
