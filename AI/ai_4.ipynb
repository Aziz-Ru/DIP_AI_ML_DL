{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeee787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def load_dataset(name):\n",
    "    if name == \"MNIST\":\n",
    "        return tf.keras.datasets.mnist.load_data()\n",
    "    elif name == \"Fashion-MNIST\":\n",
    "        return tf.keras.datasets.fashion_mnist.load_data()\n",
    "    elif name == \"CIFAR-10\":\n",
    "        return tf.keras.datasets.cifar10.load_data()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dataset\")\n",
    "\n",
    "\n",
    "def preprocess_data(x, y, num_channels=1):\n",
    "    x = x.astype(\"float32\") / 255.0\n",
    "    if num_channels == 3 and x.shape[-1] != 3:\n",
    "        x = tf.image.grayscale_to_rgb(tf.expand_dims(x, -1))\n",
    "    elif num_channels == 1 and len(x.shape) == 3:\n",
    "        x = x[..., None]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def build_cnn(input_shape, num_classes=10):\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=input_shape),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "datasets = [\"MNIST\", \"Fashion-MNIST\", \"CIFAR-10\"]\n",
    "results = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7509b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/silicon/dip_ai/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on MNIST...\n",
      "Epoch 1/15\n",
      "938/938 - 9s - 10ms/step - accuracy: 0.9531 - loss: 0.1601 - val_accuracy: 0.9840 - val_loss: 0.0495\n",
      "Epoch 2/15\n",
      "938/938 - 8s - 8ms/step - accuracy: 0.9853 - loss: 0.0474 - val_accuracy: 0.9881 - val_loss: 0.0363\n",
      "Epoch 3/15\n",
      "938/938 - 9s - 10ms/step - accuracy: 0.9900 - loss: 0.0320 - val_accuracy: 0.9898 - val_loss: 0.0323\n",
      "Epoch 4/15\n",
      "938/938 - 9s - 9ms/step - accuracy: 0.9923 - loss: 0.0238 - val_accuracy: 0.9906 - val_loss: 0.0305\n",
      "Epoch 5/15\n",
      "938/938 - 9s - 9ms/step - accuracy: 0.9942 - loss: 0.0180 - val_accuracy: 0.9902 - val_loss: 0.0287\n",
      "Epoch 6/15\n",
      "938/938 - 8s - 9ms/step - accuracy: 0.9955 - loss: 0.0138 - val_accuracy: 0.9901 - val_loss: 0.0317\n",
      "Epoch 7/15\n",
      "938/938 - 9s - 9ms/step - accuracy: 0.9962 - loss: 0.0122 - val_accuracy: 0.9912 - val_loss: 0.0270\n",
      "Epoch 8/15\n",
      "938/938 - 8s - 9ms/step - accuracy: 0.9972 - loss: 0.0082 - val_accuracy: 0.9906 - val_loss: 0.0343\n",
      "Epoch 9/15\n",
      "938/938 - 8s - 9ms/step - accuracy: 0.9971 - loss: 0.0085 - val_accuracy: 0.9902 - val_loss: 0.0343\n",
      "Epoch 10/15\n",
      "938/938 - 9s - 10ms/step - accuracy: 0.9978 - loss: 0.0057 - val_accuracy: 0.9904 - val_loss: 0.0341\n",
      "Epoch 11/15\n",
      "938/938 - 10s - 11ms/step - accuracy: 0.9976 - loss: 0.0070 - val_accuracy: 0.9912 - val_loss: 0.0339\n",
      "Epoch 12/15\n",
      "938/938 - 10s - 11ms/step - accuracy: 0.9983 - loss: 0.0050 - val_accuracy: 0.9905 - val_loss: 0.0394\n",
      "Epoch 13/15\n",
      "938/938 - 10s - 10ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 0.9876 - val_loss: 0.0524\n",
      "Epoch 14/15\n",
      "938/938 - 10s - 10ms/step - accuracy: 0.9985 - loss: 0.0047 - val_accuracy: 0.9904 - val_loss: 0.0417\n",
      "Epoch 15/15\n",
      "938/938 - 9s - 10ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.9905 - val_loss: 0.0446\n",
      "Test Accuracy on MNIST: 0.9905\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1us/step\n",
      "\n",
      "Training on Fashion-MNIST...\n",
      "Epoch 1/15\n",
      "938/938 - 10s - 10ms/step - accuracy: 0.8221 - loss: 0.4908 - val_accuracy: 0.8612 - val_loss: 0.3924\n",
      "Epoch 2/15\n",
      "938/938 - 10s - 10ms/step - accuracy: 0.8821 - loss: 0.3280 - val_accuracy: 0.8874 - val_loss: 0.3168\n",
      "Epoch 3/15\n",
      "938/938 - 10s - 10ms/step - accuracy: 0.8982 - loss: 0.2809 - val_accuracy: 0.8931 - val_loss: 0.2960\n",
      "Epoch 4/15\n",
      "938/938 - 10s - 10ms/step - accuracy: 0.9084 - loss: 0.2517 - val_accuracy: 0.9002 - val_loss: 0.2698\n",
      "Epoch 5/15\n",
      "938/938 - 11s - 11ms/step - accuracy: 0.9172 - loss: 0.2258 - val_accuracy: 0.9043 - val_loss: 0.2660\n",
      "Epoch 6/15\n",
      "938/938 - 11s - 12ms/step - accuracy: 0.9239 - loss: 0.2043 - val_accuracy: 0.9085 - val_loss: 0.2614\n",
      "Epoch 7/15\n",
      "938/938 - 12s - 13ms/step - accuracy: 0.9311 - loss: 0.1845 - val_accuracy: 0.9067 - val_loss: 0.2602\n",
      "Epoch 8/15\n",
      "938/938 - 15s - 16ms/step - accuracy: 0.9379 - loss: 0.1662 - val_accuracy: 0.9124 - val_loss: 0.2508\n",
      "Epoch 9/15\n",
      "938/938 - 17s - 18ms/step - accuracy: 0.9445 - loss: 0.1493 - val_accuracy: 0.9131 - val_loss: 0.2529\n",
      "Epoch 10/15\n",
      "938/938 - 18s - 20ms/step - accuracy: 0.9488 - loss: 0.1351 - val_accuracy: 0.9098 - val_loss: 0.2772\n",
      "Epoch 11/15\n",
      "938/938 - 20s - 21ms/step - accuracy: 0.9548 - loss: 0.1202 - val_accuracy: 0.9137 - val_loss: 0.2683\n",
      "Epoch 12/15\n",
      "938/938 - 18s - 19ms/step - accuracy: 0.9591 - loss: 0.1079 - val_accuracy: 0.9136 - val_loss: 0.2882\n",
      "Epoch 13/15\n",
      "938/938 - 17s - 18ms/step - accuracy: 0.9643 - loss: 0.0949 - val_accuracy: 0.9095 - val_loss: 0.3020\n",
      "Epoch 14/15\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9679 - loss: 0.0860 - val_accuracy: 0.9165 - val_loss: 0.3085\n",
      "Epoch 15/15\n",
      "938/938 - 17s - 19ms/step - accuracy: 0.9702 - loss: 0.0777 - val_accuracy: 0.9129 - val_loss: 0.3196\n",
      "Test Accuracy on Fashion-MNIST: 0.9129\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m568s\u001b[0m 3us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incomplete or corrupted file detected. The auto file hash does not match the provided value of 6d958be074577803d12ecdefd02955f39262c83c16fe9348329d7fe0b5c001ce.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m dataset_name \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     (x_train, y_train), (x_test, y_test) = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     channels = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dataset_name != \u001b[33m\"\u001b[39m\u001b[33mCIFAR-10\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m3\u001b[39m\n\u001b[32m      4\u001b[39m     x_train, y_train = preprocess_data(x_train, y_train, num_channels=channels)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tf.keras.datasets.fashion_mnist.load_data()\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name == \u001b[33m\"\u001b[39m\u001b[33mCIFAR-10\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcifar10\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnknown dataset\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dip_ai/.venv/lib/python3.12/site-packages/keras/src/datasets/cifar10.py:65\u001b[39m, in \u001b[36mload_data\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     63\u001b[39m dirname = \u001b[33m\"\u001b[39m\u001b[33mcifar-10-batches-py-target\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     64\u001b[39m origin = \u001b[33m\"\u001b[39m\u001b[33mhttps://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m path = \u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m=\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: E501\u001b[39;49;00m\n\u001b[32m     70\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m6d958be074577803d12ecdefd02955f39262c83c16fe9348329d7fe0b5c001ce\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m num_train_samples = \u001b[32m50000\u001b[39m\n\u001b[32m     76\u001b[39m x_train = np.empty((num_train_samples, \u001b[32m3\u001b[39m, \u001b[32m32\u001b[39m, \u001b[32m32\u001b[39m), dtype=\u001b[33m\"\u001b[39m\u001b[33muint8\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dip_ai/.venv/lib/python3.12/site-packages/keras/src/utils/file_utils.py:328\u001b[39m, in \u001b[36mget_file\u001b[39m\u001b[34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir, force_download)\u001b[39m\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(download_target) \u001b[38;5;129;01mand\u001b[39;00m file_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    325\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validate_file(\n\u001b[32m    326\u001b[39m             download_target, file_hash, algorithm=hash_algorithm\n\u001b[32m    327\u001b[39m         ):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    329\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mIncomplete or corrupted file detected. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    330\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhash_algorithm\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    331\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfile hash does not match the provided value \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    332\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    333\u001b[39m             )\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extract \u001b[38;5;129;01mor\u001b[39;00m untar:\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m untar:\n",
      "\u001b[31mValueError\u001b[39m: Incomplete or corrupted file detected. The auto file hash does not match the provided value of 6d958be074577803d12ecdefd02955f39262c83c16fe9348329d7fe0b5c001ce."
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets:\n",
    "    (x_train, y_train), (x_test, y_test) = load_dataset(dataset_name)\n",
    "    channels = 1 if dataset_name != \"CIFAR-10\" else 3\n",
    "    x_train, y_train = preprocess_data(x_train, y_train, num_channels=channels)\n",
    "    x_test, y_test = preprocess_data(x_test, y_test, num_channels=channels)\n",
    "\n",
    "    model = build_cnn(x_train.shape[1:], num_classes=10)\n",
    "    print(f\"\\nTraining on {dataset_name}...\")\n",
    "    model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=15, batch_size=64, verbose=2)\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"Test Accuracy on {dataset_name}: {test_acc:.4f}\")\n",
    "    results[dataset_name] = test_acc\n",
    "\n",
    "print(\"\\nFinal Test Accuracies:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97794f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv_learn (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
